{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "        Compute importance score for a sample x, over time and features\n",
    "        :param x: Sample instance to evaluate score for. Shape:[batch, features, time]\n",
    "        :param n_samples: number of Monte-Carlo samples\n",
    "        :return: Importance score matrix of shape:[batch, features, time]\n",
    "        \"\"\"\n",
    "a = np.array([\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  1,\n",
       "        2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  1,  2,\n",
       "        3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,  1,  2,  3,\n",
       "        4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = a.reshape(-1)\n",
    "r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试FO及AFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  0,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  2,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  1,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5, -2,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.copy()\n",
    "c[:, 1, 1] = np.random.uniform(-3, +3, size=(len(a),))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "T1 = torch.tensor([[[[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [7, 8, 9]],\n",
    "                 [[10, 11, 12],\n",
    "                 [13, 14, 15],\n",
    "                 [16, 17, 18]],\n",
    "                 [[19, 20, 21],\n",
    "                 [22, 23, 24],\n",
    "                 [25, 26, 27]]],\n",
    "                 [[[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [7, 8, 9]],\n",
    "                 [[10, 11, 12],\n",
    "                 [13, 14, 15],\n",
    "                 [16, 17, 18]],\n",
    "                 [[19, 20, 21],\n",
    "                 [22, 23, 24],\n",
    "                 [25, 26, 27]]]])\n",
    "print(T1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.stack([x[0] for x in T1])\n",
    "a.shape\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b tensor([4, 5, 6, 4, 5, 6])\n",
      "c [4 6]\n"
     ]
    }
   ],
   "source": [
    "b = a[:,1,:].reshape(-1)\n",
    "print('b',b)\n",
    "c = np.random.choice(b, size=(2,))\n",
    "print('c',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [7, 8, 9]]]) torch.Size([2, 2, 3]) tensor([[[7, 8, 9]],\n",
      "\n",
      "        [[7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "b_all = a[:,1:,:]\n",
    "# c_all = a[:,2:,:]\n",
    "print(b_all,b_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 7],\n",
      "        [5, 8],\n",
      "        [6, 9],\n",
      "        [4, 7],\n",
      "        [5, 8],\n",
      "        [6, 9]]) torch.Size([6, 2]) tensor([[7],\n",
      "        [8],\n",
      "        [9],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n"
     ]
    }
   ],
   "source": [
    "b_tran = np.transpose(b_all, (0, 2, 1)).reshape(b_all.shape[0] * b_all.shape[2], -1)\n",
    "# c_tran = np.transpose(c_all, (0, 2, 1)).reshape(c_all.shape[0] * c_all.shape[2], -1)\n",
    "print(b_tran, b_tran.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6, 4, 5, 6],\n",
       "        [7, 8, 9, 7, 8, 9]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_new = b_tran.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 5, 5],\n",
       "        [9, 8, 8]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b_tran[np.random.choice(b_tran.shape[0], size=3, replace=False), :]\n",
    "c.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 6 1]\n",
      " [3 2 2]\n",
      " [3 4 5]] 10\n",
      "[[0 3 3 3]\n",
      " [1 6 2 4]\n",
      " [2 1 2 5]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0, 1, 2],\n",
    "              [3, 4, 5],\n",
    "              [6, 7, 8],\n",
    "              [9, 7, 6],\n",
    "              [3, 2, 2],\n",
    "              [0, 1, 0],\n",
    "              [1, 3, 1],\n",
    "              [0, 4, 1],\n",
    "              [2, 4, 2],\n",
    "              [3, 6, 1]])\n",
    "\n",
    "B = A[np.random.choice(A.shape[0], size=4, replace=False), :]\n",
    "print(B,A.shape[0])\n",
    "print(B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[4, 7],\n",
    "          [5, 8],\n",
    "          [6, 9], \n",
    "          [4, 7],\n",
    "          [5, 8],\n",
    "          [6, 9]]).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试TFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFSExplainer:\n",
    "    def __init__(self, model, train_loader, activation=torch.nn.Softmax(-1)):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.base_model = model.to(self.device)\n",
    "        trainset = list(train_loader.dataset)\n",
    "        self.data_distribution = torch.stack([x[0] for x in trainset]) # torch.stack()，沿着一个新维度对输入向量序列进行连接，增加新的维度堆叠已有张量（2->3,3->4）\n",
    "        self.activation = activation\n",
    "\n",
    "    def attribute(self, x, y, retrospective=False):\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        _, n_features, t_len = x.shape\n",
    "        score = np.zeros(x.shape)\n",
    "        if retrospective:\n",
    "            p_y_t = self.activation(self.base_model(x))\n",
    "\n",
    "        for t in range(1, t_len):\n",
    "            if not retrospective:\n",
    "                p_y_t = self.activation(self.base_model(x[:, :, : t + 1]))\n",
    "            for i in range(n_features):\n",
    "                # reshape(-1)的作用是将数组变为一维,即从多个时间点对应的相同特征进行选取\n",
    "                feature_dist_z = np.array(self.data_distribution[:, i:, :])\n",
    "                feature_dist_o = np.array(self.data_distribution[:, i+1:, :])\n",
    "                x_hat_z = x[:, :, 0 : t + 1].clone()\n",
    "                x_hat_o = x[:, :, 0 : t + 1].clone()\n",
    "                kl_all = []\n",
    "                for _ in range(10):\n",
    "                    # 从x的训练集特征分布中采样t时刻的特征i，\n",
    "                    feature_seed = np.random.randint(0,t_len,dtype='int')\n",
    "                    x_hat_z[:, i:, t] = feature_dist_z[:,:,feature_seed]\n",
    "                    x_hat_o[:, i+1:, t] = feature_dist_o[:,:,feature_seed]\n",
    "                    y_hat_t = self.activation(self.base_model(x_hat_z))\n",
    "                    y_hat_o = self.activation(self.base_model(x_hat_o))\n",
    "                    # kl = torch.nn.KLDivLoss(reduction='none')(torch.log(y_hat_t), p_y_t)\n",
    "                    kl = torch.abs((y_hat_t) - (y_hat_o))\n",
    "                    # kl_all.append(torch.sum(kl, -1).cpu().detach().numpy())\n",
    "                    kl_all.append(np.mean(kl.detach().cpu().numpy(), -1))\n",
    "                E_kl = np.mean(np.array(kl_all), axis=0)\n",
    "                # score[:, i, t] = 2./(1+np.exp(-1*E_kl)) - 1.\n",
    "                score[:, i, t] = E_kl\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84225097 0.67060092 0.7458979  0.20037179]\n",
      " [0.33706542 0.46889425 0.56240141 0.22768581]\n",
      " [0.42327018 0.36010712 0.37087937 0.7257854 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 生成一个3x4x5的随机三维数组\n",
    "arr = np.random.rand(3, 4, 5)\n",
    "\n",
    "# 随机抽取一个二维数组\n",
    "dim = np.random.randint(0, 5)\n",
    "sub_arr = arr[:,:,dim]\n",
    "\n",
    "print(sub_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 2)\n",
      "(4, 4)\n",
      "[[[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 14]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 14]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 14]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 14]]]\n",
      "[[ 3  7 11 15]\n",
      " [ 3  7 11 15]\n",
      " [ 3  7 11 15]\n",
      " [ 3  7 11 15]]\n"
     ]
    }
   ],
   "source": [
    "x_o = a[:,:,0:2].copy()\n",
    "z_o = a[:,:,np.random.randint(0, a.shape[1], dtype='int')].copy()\n",
    "print(x_o.shape)\n",
    "print(z_o.shape)\n",
    "print(x_o)\n",
    "print(z_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_with_j [[[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]]\n",
      "x_o [[[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 10]\n",
      "  [13 15]]]\n",
      "x_no_j [[[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]]\n",
      "x_o [[[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]\n",
      "\n",
      " [[ 1  2]\n",
      "  [ 5  6]\n",
      "  [ 9 11]\n",
      "  [13 15]]]\n"
     ]
    }
   ],
   "source": [
    "x_o[:,3:,-1] = z_o[:,3:]\n",
    "x_with_j = x_o\n",
    "print('x_with_j',x_with_j)\n",
    "print('x_o',x_o)\n",
    "x_o[:,2:,-1] = z_o[:,2:]\n",
    "x_no_j = x_o\n",
    "print('x_no_j',x_no_j)\n",
    "print('x_o',x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_len = 4\n",
    "n_features = 4\n",
    "n_samples = 3\n",
    "for t in range(1, t_len):\n",
    "\n",
    "            for i in range(n_features):\n",
    "                div_all=[]\n",
    "                x_o = a[:,:,0:t+1].copy()\n",
    "                for _ in range(n_samples):\n",
    "                    z_o = a[:,:,np.random.randint(0, a.shape[1], dtype='int')].copy()\n",
    "                    x_o[:,i+1:,t] = z_o[:,i+1:]\n",
    "                    x_with_j = x_o\n",
    "                    x_o[:,i:,t] = z_o[:,i:]\n",
    "                    x_no_j = x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFS:\n",
    "    def __init__(self, model, activation=torch.nn.Softmax(-1)):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.base_model = model.to(self.device)\n",
    "        self.activation = activation\n",
    "\n",
    "    def attribute(self, x, y, n_samples=10, distance_metric='kl'):\n",
    "        \"\"\"\n",
    "        Compute importance score for a sample x, over time and features\n",
    "        :param x: Sample instance to evaluate score for. Shape:[batch, features, time]\n",
    "        :param n_samples: number of Monte-Carlo samples\n",
    "        :return: Importance score matrix of shape:[batch, features, time]\n",
    "        \"\"\"\n",
    "        x = x.to(self.device)\n",
    "        _, n_features, t_len = x.shape\n",
    "        score = np.zeros(list(x.shape))\n",
    "\n",
    "        for t in range(1, t_len):\n",
    "\n",
    "            for i in range(n_features):\n",
    "                div_all=[]\n",
    "                x_o = x[:,:,0:t+1].clone()\n",
    "                # gap = 5\n",
    "                # low = (t - gap) if (t - gap) > 0 else 0\n",
    "                # high = (t + gap) if (t + gap) < x.shape[2] else x.shape[2]\n",
    "                # for _ in range(n_samples):\n",
    "                #     range_list = np.random.randint(low, high, dtype='int')\n",
    "                #     z_o = x[:,:,range_list].clone()\n",
    "                for _ in range(n_samples):\n",
    "                    z_o = x[:,:,np.random.randint(0, x.shape[2], dtype='int')].clone()\n",
    "                    x_o[:,i+1:,t] = z_o[:,i+1:]\n",
    "                    x_with_j = x_o\n",
    "                    x_o[:,i:,t] = z_o[:,i:]\n",
    "                    x_no_j = x_o\n",
    "                    y_with_j = self.activation(self.base_model(x_with_j))\n",
    "                    y_no_j = self.activation(self.base_model(x_no_j))\n",
    "                    div = torch.abs(y_with_j-y_no_j)\n",
    "                    div_all.append(np.mean(div.detach().cpu().numpy(), -1))\n",
    "                E_div = np.mean(np.array(div_all),axis=0)\n",
    "                score[:, i, t] = E_div\n",
    "        return score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试MIMIC数据上的TFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import logging\n",
    "class BaseExplainer(abc.ABC):\n",
    "    \"\"\"\n",
    "    A base class for explainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=None):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "\n",
    "        Args:\n",
    "            device:\n",
    "               The torch device.\n",
    "        \"\"\"\n",
    "        self.base_model: TorchModel | None = None\n",
    "        self.device = resolve_device(device)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def attribute(self, x):\n",
    "        \"\"\"\n",
    "        The attribution method that the explainer will give.\n",
    "        Args:\n",
    "            x:\n",
    "                The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            The attribution with respect to x. The shape should be the same as x, or it could\n",
    "            be one dimension greater than x if there is aggregation needed.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def train_generators(\n",
    "        self, train_loader, valid_loader, num_epochs=300\n",
    "    ) -> GeneratorTrainingResults | None:\n",
    "        \"\"\"\n",
    "        If the explainer or attribution method needs a generator, this will train the generator.\n",
    "\n",
    "        Args:\n",
    "            train_loader:\n",
    "                The dataloader for training\n",
    "            valid_loader:\n",
    "                The dataloader for validation.\n",
    "            num_epochs:\n",
    "                The number of epochs.\n",
    "\n",
    "        Returns:\n",
    "            The training results for the generator, if applicable. This includes the\n",
    "            training curves.\n",
    "\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def test_generators(self, test_loader) -> float | None:\n",
    "        \"\"\"\n",
    "        If the explainer or attribution method needs a generator, this will return the performance\n",
    "        of the generator on the test set.\n",
    "\n",
    "        Args:\n",
    "            test_loader:\n",
    "                The dataloader for testing.\n",
    "\n",
    "        Returns:\n",
    "            The test result (MSE) for the generator, if applicable.\n",
    "\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def load_generators(self) -> None:\n",
    "        \"\"\"\n",
    "        If the explainer or attribution method needs a generator, this will load the generator from\n",
    "        the disk.\n",
    "        \"\"\"\n",
    "\n",
    "    def set_model(self, model, set_eval=True) -> None:\n",
    "        \"\"\"\n",
    "        Set the base model the explainer wish to explain.\n",
    "\n",
    "        Args:\n",
    "            model:\n",
    "                The base model.\n",
    "            set_eval:\n",
    "                Indicating whether we set to eval mode for the explainer. Note that in some cases\n",
    "                like Dynamask or FIT, they do not set the model to eval mode.\n",
    "        \"\"\"\n",
    "        self.base_model = model\n",
    "        if set_eval:\n",
    "            self.base_model.eval()\n",
    "        self.base_model.to(self.device)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        \"\"\"\n",
    "        Return the name of the explainer.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFSExplainer(BaseExplainer):\n",
    "\n",
    "    def __init__(self, device, n_samples=10, **kwargs):\n",
    "        super().__init__(device)\n",
    "        self.n_samples = n_samples\n",
    "        if len(kwargs) > 0:\n",
    "            log = logging.getLogger(TFSExplainer.__name__)\n",
    "            log.warning(f\"kwargs is not empty. Unused kwargs={kwargs}\")\n",
    "\n",
    "    def attribute(self, x):\n",
    "        \"\"\"\n",
    "        Compute importance score for a sample x, over time and features\n",
    "        :param x: Sample instance to evaluate score for. Shape:[batch, features, time]\n",
    "        :param n_samples: number of Monte-Carlo samples\n",
    "        :return: Importance score matrix of shape:[batch, features, time]\n",
    "        \"\"\"\n",
    "        self.base_model.eval()\n",
    "        self.base_model.zero_grad()\n",
    "\n",
    "        x = x.to(self.device)\n",
    "        _, n_features, t_len = x.shape\n",
    "        score = np.zeros(list(x.shape))\n",
    "\n",
    "        for t in range(1, t_len):\n",
    "\n",
    "            for i in range(n_features):\n",
    "                div_all=[]\n",
    "                x_o = x[:,:,0:t+1].clone()\n",
    "                for _ in range(self.n_samples):\n",
    "                    z_o = x[:,:,np.random.randint(0, x.shape[1], dtype='int')].clone()\n",
    "                    x_o[:,i+1:,t] = z_o[:,i+1:]\n",
    "                    x_with_j = x_o\n",
    "                    x_o[:,i:,t] = z_o[:,i:]\n",
    "                    x_no_j = x_o\n",
    "                    y_with_j = self.base_model.predict(self.base_model(x_with_j))\n",
    "                    y_no_j = self.base_model.predict(self.base_model(x_no_j))\n",
    "                    div = torch.abs(y_with_j-y_no_j)\n",
    "                    div_all.append(np.mean(div.detach().cpu().numpy(), -1))\n",
    "                E_div = np.mean(np.array(div_all),axis=0)\n",
    "                score[:, i, t] = E_div\n",
    "        return score\n",
    "\n",
    "    def get_name(self):\n",
    "        if self.n_samples != 10:\n",
    "            return f\"tfs_sample_{self.n_samples}\"\n",
    "        return \"tfs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
