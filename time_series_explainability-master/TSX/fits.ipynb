{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]],\n",
       "\n",
       "       [[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [13, 14, 15, 16]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "        Compute importance score for a sample x, over time and features\n",
    "        :param x: Sample instance to evaluate score for. Shape:[batch, features, time]\n",
    "        :param n_samples: number of Monte-Carlo samples\n",
    "        :return: Importance score matrix of shape:[batch, features, time]\n",
    "        \"\"\"\n",
    "a = np.array([\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],\n",
    "    [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]],])\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试FO及AFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.copy()\n",
    "c[:, 1, 1] = np.random.uniform(-3, +3, size=(len(a),))\n",
    "c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试TFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o = a[:,:,0:2]\n",
    "z_o = a[:,:,np.random.randint(0, a.shape[1], dtype='int')]\n",
    "print(x_o.shape)\n",
    "print(z_o.shape)\n",
    "print(x_o)\n",
    "print(z_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o[:,3:,-1] = z_o[:,3:]\n",
    "x_with_j = x_o\n",
    "print(x_with_j)\n",
    "x_o[:,2:,-1] = z_o[:,2:]\n",
    "x_no_j = x_o\n",
    "print(x_no_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_len = 4\n",
    "n_features = 4\n",
    "n_samples = 3\n",
    "for t in range(1, t_len):\n",
    "\n",
    "            for i in range(n_features):\n",
    "                div_all=[]\n",
    "                x_o = a[:,:,0:t+1].copy()\n",
    "                for _ in range(n_samples):\n",
    "                    z_o = a[:,:,np.random.randint(0, a.shape[1], dtype='int')].copy()\n",
    "                    x_o[:,i+1:,t] = z_o[:,i+1:]\n",
    "                    x_with_j = x_o\n",
    "                    x_o[:,i:,t] = z_o[:,i:]\n",
    "                    x_no_j = x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFS:\n",
    "    def __init__(self, model, activation=torch.nn.Softmax(-1)):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.base_model = model.to(self.device)\n",
    "        self.activation = activation\n",
    "\n",
    "    def attribute(self, x, y, n_samples=10):\n",
    "        \"\"\"\n",
    "        Compute importance score for a sample x, over time and features\n",
    "        :param x: Sample instance to evaluate score for. Shape:[batch, features, time]\n",
    "        :param n_samples: number of Monte-Carlo samples\n",
    "        :return: Importance score matrix of shape:[batch, features, time]\n",
    "        \"\"\"\n",
    "        x = x.to(self.device)\n",
    "        _, n_features, t_len = x.shape\n",
    "        score = np.zeros(list(x.shape))\n",
    "\n",
    "        for t in range(1, t_len):\n",
    "\n",
    "            for i in range(n_features):\n",
    "                div_all=[]\n",
    "                for _ in range(n_samples):\n",
    "                    x_o = x[:,:,t].clone()\n",
    "                    z_o = x[:,:,np.random.randint(0, x.shape[1], dtype='int')].clone()\n",
    "                    x_o[:,i:,t] = z_o[:,i:]\n",
    "                    x_with_j = x_o\n",
    "                    x_o[:,i-1:,t] = z_o[:,i-1:]\n",
    "                    x_no_j = x_o\n",
    "                    y_with_j = self.activation(self.base_model(x_with_j))\n",
    "                    y_no_j = self.activation(self.base_model(x_no_j))\n",
    "                    div = torch.abs(y_with_j-y_no_j)\n",
    "                    div_all.append(np.mean(div.detach().cpu().numpy(), -1))\n",
    "                E_div = np.mean(np.array(div_all),axis=0)\n",
    "                score[:, i, t] = E_div\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import logging\n",
    "class BaseExplainer(abc.ABC):\n",
    "    \"\"\"\n",
    "    A base class for explainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=None):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "\n",
    "        Args:\n",
    "            device:\n",
    "               The torch device.\n",
    "        \"\"\"\n",
    "        self.base_model: TorchModel | None = None\n",
    "        self.device = resolve_device(device)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def attribute(self, x):\n",
    "        \"\"\"\n",
    "        The attribution method that the explainer will give.\n",
    "        Args:\n",
    "            x:\n",
    "                The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            The attribution with respect to x. The shape should be the same as x, or it could\n",
    "            be one dimension greater than x if there is aggregation needed.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def train_generators(\n",
    "        self, train_loader, valid_loader, num_epochs=300\n",
    "    ) -> GeneratorTrainingResults | None:\n",
    "        \"\"\"\n",
    "        If the explainer or attribution method needs a generator, this will train the generator.\n",
    "\n",
    "        Args:\n",
    "            train_loader:\n",
    "                The dataloader for training\n",
    "            valid_loader:\n",
    "                The dataloader for validation.\n",
    "            num_epochs:\n",
    "                The number of epochs.\n",
    "\n",
    "        Returns:\n",
    "            The training results for the generator, if applicable. This includes the\n",
    "            training curves.\n",
    "\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def test_generators(self, test_loader) -> float | None:\n",
    "        \"\"\"\n",
    "        If the explainer or attribution method needs a generator, this will return the performance\n",
    "        of the generator on the test set.\n",
    "\n",
    "        Args:\n",
    "            test_loader:\n",
    "                The dataloader for testing.\n",
    "\n",
    "        Returns:\n",
    "            The test result (MSE) for the generator, if applicable.\n",
    "\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def load_generators(self) -> None:\n",
    "        \"\"\"\n",
    "        If the explainer or attribution method needs a generator, this will load the generator from\n",
    "        the disk.\n",
    "        \"\"\"\n",
    "\n",
    "    def set_model(self, model, set_eval=True) -> None:\n",
    "        \"\"\"\n",
    "        Set the base model the explainer wish to explain.\n",
    "\n",
    "        Args:\n",
    "            model:\n",
    "                The base model.\n",
    "            set_eval:\n",
    "                Indicating whether we set to eval mode for the explainer. Note that in some cases\n",
    "                like Dynamask or FIT, they do not set the model to eval mode.\n",
    "        \"\"\"\n",
    "        self.base_model = model\n",
    "        if set_eval:\n",
    "            self.base_model.eval()\n",
    "        self.base_model.to(self.device)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        \"\"\"\n",
    "        Return the name of the explainer.\n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试MIMIC数据上的TFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFSExplainer(BaseExplainer):\n",
    "\n",
    "    def __init__(self, device, n_samples=10, **kwargs):\n",
    "        super().__init__(device)\n",
    "        self.n_samples = n_samples\n",
    "        if len(kwargs) > 0:\n",
    "            log = logging.getLogger(TFSExplainer.__name__)\n",
    "            log.warning(f\"kwargs is not empty. Unused kwargs={kwargs}\")\n",
    "\n",
    "    def attribute(self, x):\n",
    "        \"\"\"\n",
    "        Compute importance score for a sample x, over time and features\n",
    "        :param x: Sample instance to evaluate score for. Shape:[batch, features, time]\n",
    "        :param n_samples: number of Monte-Carlo samples\n",
    "        :return: Importance score matrix of shape:[batch, features, time]\n",
    "        \"\"\"\n",
    "        self.base_model.eval()\n",
    "        self.base_model.zero_grad()\n",
    "\n",
    "        x = x.to(self.device)\n",
    "        _, n_features, t_len = x.shape\n",
    "        score = np.zeros(list(x.shape))\n",
    "\n",
    "        for t in range(1, t_len):\n",
    "\n",
    "            for i in range(n_features):\n",
    "                div_all=[]\n",
    "                x_o = x[:,:,0:t+1].clone()\n",
    "                for _ in range(self.n_samples):\n",
    "                    z_o = x[:,:,np.random.randint(0, x.shape[1], dtype='int')].clone()\n",
    "                    x_o[:,i+1:,t] = z_o[:,i+1:]\n",
    "                    x_with_j = x_o\n",
    "                    x_o[:,i:,t] = z_o[:,i:]\n",
    "                    x_no_j = x_o\n",
    "                    y_with_j = self.base_model.predict(self.base_model(x_with_j))\n",
    "                    y_no_j = self.base_model.predict(self.base_model(x_no_j))\n",
    "                    div = torch.abs(y_with_j-y_no_j)\n",
    "                    div_all.append(np.mean(div.detach().cpu().numpy(), -1))\n",
    "                E_div = np.mean(np.array(div_all),axis=0)\n",
    "                score[:, i, t] = E_div\n",
    "        return score\n",
    "\n",
    "    def get_name(self):\n",
    "        if self.n_samples != 10:\n",
    "            return f\"tfs_sample_{self.n_samples}\"\n",
    "        return \"tfs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
